{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Analytics-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3DxPCznjdU-M",
        "rZHbiVQWNoHT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f69136a36504d6b99490b96108fc56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7793fb0876d94098a1596db099a67c20",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_62457700621b4a648af5339656da2c9e",
              "IPY_MODEL_ce26eb9a27394f47b02fc474111e5f9e"
            ]
          }
        },
        "7793fb0876d94098a1596db099a67c20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62457700621b4a648af5339656da2c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6314409480254be7809c5b9166fcee53",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa458488167844ddb83f66aec14fc551"
          }
        },
        "ce26eb9a27394f47b02fc474111e5f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc91a9301e1f4464953401d0de4e6463",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00f81813b319408f9da640eaf22837b3"
          }
        },
        "6314409480254be7809c5b9166fcee53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa458488167844ddb83f66aec14fc551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc91a9301e1f4464953401d0de4e6463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00f81813b319408f9da640eaf22837b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "542ea83b34a64b8e8651b8a32c6236d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d6c32e2a68d4b4c948e3fc4d401a8ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_587ec64aae6e4eb5aa63fb1c0af2dd65",
              "IPY_MODEL_45d4bebdef074fd6b1c07eaf868f670d"
            ]
          }
        },
        "1d6c32e2a68d4b4c948e3fc4d401a8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "587ec64aae6e4eb5aa63fb1c0af2dd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_455c523fa7354e158876aa1ef2ec1d70",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8771dec778540d484362d2877f34d4e"
          }
        },
        "45d4bebdef074fd6b1c07eaf868f670d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_edf53b600eea44b1b83cdb46494aa34b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 4.57kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bffaf67cfd6d4430816d5aaa3b542780"
          }
        },
        "455c523fa7354e158876aa1ef2ec1d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8771dec778540d484362d2877f34d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edf53b600eea44b1b83cdb46494aa34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bffaf67cfd6d4430816d5aaa3b542780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3580bffd19534129a52e6306ccb858b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac544c4718fd4bdb852a3ee881a712c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e5044ab630345e2be10c542313964ea",
              "IPY_MODEL_bf8431f64ade4b9ea469cbd26a814801"
            ]
          }
        },
        "ac544c4718fd4bdb852a3ee881a712c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e5044ab630345e2be10c542313964ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_64308d2811b54e159af7ba0d901da5a4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecb44e43bf7f4cdab17406acc813dd31"
          }
        },
        "bf8431f64ade4b9ea469cbd26a814801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_285a28208a4c4362b29aeec70d824588",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 61.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_557dee5054a24e6caad8598ec4635d5d"
          }
        },
        "64308d2811b54e159af7ba0d901da5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecb44e43bf7f4cdab17406acc813dd31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "285a28208a4c4362b29aeec70d824588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "557dee5054a24e6caad8598ec4635d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MateoGonzalez/text-analytics-project/blob/main/Text_Analytics_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1R0B8pzuJbH"
      },
      "source": [
        "# Libraries Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLPKuG8kBi5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2452dea6-23e5-4f51-a3bf-b272e325aa8c"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import gc\r\n",
        "\r\n",
        "import random\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "# set a seed value\r\n",
        "torch.manual_seed(555)\r\n",
        "\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "!pip install transformers\r\n",
        "import transformers\r\n",
        "from transformers import BertTokenizer, BertForSequenceClassification \r\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\r\n",
        "from transformers import AdamW\r\n",
        "from transformers import AutoModel, BertTokenizerFast\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "\r\n",
        "print(torch.__version__)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMOrCYdjTnlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568efff2-e218-4e5b-8ad1-15a701f13dd3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim.models import Doc2Vec"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57D4U3xEVc-S"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX35wEKtNB1J"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwZ8lGf1NEGd"
      },
      "source": [
        "# this function allow to load a df from google drive\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "def load_df(path, name):\n",
        "  drive.mount('/content/drive',force_remount=True)\n",
        "  project_dir = path\n",
        "\n",
        "  os.chdir(project_dir)\n",
        "  df = pd.read_csv(project_dir + name)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSq1TBRmNJsl"
      },
      "source": [
        "# this function take two columns of a dataframe and return a list of their concatenation\n",
        "def concatenate_sentences(col_1, col_2):\n",
        "  sentences= list()\n",
        "\n",
        "  for i in range( 0, len(col_1) ):\n",
        "    sentences.append( col_1[i] + col_2[i] )\n",
        "\n",
        "  return sentences\n",
        "\n",
        "# example\n",
        "#list_of_sentences= concatenate_sentences(df['premise'],df['hypothesis'])\n",
        "#list_of_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4djdlNjDNKTN"
      },
      "source": [
        "# this function take a list of sentences, then it return the right input for word embending model\n",
        "def prepare_input_we(sentences):\n",
        "  tok_sents= list()\n",
        "\n",
        "  for sentence in sentences:\n",
        "    tok_sents.append(word_tokenize(sentence))\n",
        "  \n",
        "  return tok_sents\n",
        "\n",
        "# example\n",
        "#tok_sents= prepare_input_we(list_of_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN44Nq_9NMuH"
      },
      "source": [
        "# this function takes a list of sentences and return the right input for doc2vec model\n",
        "def prepare_input_w2d(list_of_sentences):\n",
        "  return [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(list_of_sentences)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsyNwDUOlMX6"
      },
      "source": [
        "class TokensTensors(Dataset):\r\n",
        "\r\n",
        "    def __init__(self, df):\r\n",
        "        self.df_data = df\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "\r\n",
        "        # get the sentence from the dataframe\r\n",
        "        sentence1 = self.df_data.loc[index, 'premise']\r\n",
        "        sentence2 = self.df_data.loc[index, 'hypothesis']\r\n",
        "\r\n",
        "        # Process the sentence\r\n",
        "        # ---------------------\r\n",
        "\r\n",
        "        encoded_dict = tokenizer.encode_plus(\r\n",
        "                    sentence1, sentence2,           # Sentences to encode.\r\n",
        "                    add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\r\n",
        "                    max_length = MAX_LEN,           # Pad or truncate all sentences.\r\n",
        "                    padding = True,\r\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\r\n",
        "                    return_tensors = 'pt',          # Return pytorch tensors.\r\n",
        "                    truncation=True\r\n",
        "               )  \r\n",
        "        \r\n",
        "        # These are torch tensors already.\r\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\r\n",
        "        att_mask = encoded_dict['attention_mask'][0]\r\n",
        "        token_type_ids = encoded_dict['token_type_ids'][0]\r\n",
        "        \r\n",
        "        \r\n",
        "        if 'label' in self.df_data.columns:\r\n",
        "          # Convert the target to a torch tensor\r\n",
        "          target = torch.tensor(self.df_data.loc[index, 'label'])\r\n",
        "\r\n",
        "          sample = (padded_token_list, att_mask, token_type_ids, target)\r\n",
        "        else:\r\n",
        "          sample = (padded_token_list, att_mask, token_type_ids)\r\n",
        "\r\n",
        "        return sample\r\n",
        "\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.df_data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfiAnJR8sDLk"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzw--VCeTtx_"
      },
      "source": [
        "# Obtain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "marE3_CDRRyd"
      },
      "source": [
        "train_df_orig = pd.read_csv('https://raw.githubusercontent.com/MateoGonzalez/text-analytics-project/main/train.csv')\r\n",
        "test_df_orig = pd.read_csv('https://raw.githubusercontent.com/MateoGonzalez/text-analytics-project/main/test.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "0ZyjJF82SySr",
        "outputId": "66b3ec7d-8302-41ad-caed-020102785759"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5130fd2cb5</td>\n",
              "      <td>and these comments were considered in formulat...</td>\n",
              "      <td>The rules developed in the interim were put to...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5b72532a0b</td>\n",
              "      <td>These are issues that we wrestle with in pract...</td>\n",
              "      <td>Practice groups are not permitted to work on t...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3931fbe82a</td>\n",
              "      <td>Des petites choses comme celles-là font une di...</td>\n",
              "      <td>J'essayais d'accomplir quelque chose.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5622f0c60b</td>\n",
              "      <td>you know they can't really defend themselves l...</td>\n",
              "      <td>They can't defend themselves because of their ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86aaa48b45</td>\n",
              "      <td>ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...</td>\n",
              "      <td>เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... label\n",
              "0  5130fd2cb5  ...     0\n",
              "1  5b72532a0b  ...     2\n",
              "2  3931fbe82a  ...     0\n",
              "3  5622f0c60b  ...     0\n",
              "4  86aaa48b45  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zcS5HIoT3J0"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnAEXKkFSzFT",
        "outputId": "c0ae57f9-5eac-4ae2-d65c-1cf300647caf"
      },
      "source": [
        "print(\"train: \", train_df.shape)\r\n",
        "print(\"test: \", test_df.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:  (12120, 6)\n",
            "test:  (5195, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnGHon8jUJoQ",
        "outputId": "65f10270-38b1-4760-a895-2831b925ca9d"
      },
      "source": [
        "train_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'premise', 'hypothesis', 'lang_abv', 'language', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79lMIelqnv5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d82bd9b-105d-49ae-d29a-b86cf1e44a63"
      },
      "source": [
        "test_df.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'premise', 'hypothesis', 'lang_abv', 'language'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1pLP2b3SzTp",
        "outputId": "115a1759-afb8-4814-90ee-a10f470d8122"
      },
      "source": [
        "sns.countplot(train_df['label'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2624d02f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp6MPIrJSzfe",
        "outputId": "d47a7216-a2d6-4b73-84f2-a97fcf39502d"
      },
      "source": [
        "plt.figure(figsize=(14,4))\r\n",
        "sns.countplot(train_df['language'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f262473c438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhysQrQUSzrg"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lln91crSz00"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCFnKxXIn2CD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-IdI4OsX6YD"
      },
      "source": [
        "# Assesing data quality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSSNiLOqoAtl",
        "outputId": "ec830868-4a57-4b14-ca89-6cda4accbaec"
      },
      "source": [
        "## Is there any duplicated line?\r\n",
        "train_df[train_df.duplicated()].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id            0\n",
              "premise       0\n",
              "hypothesis    0\n",
              "lang_abv      0\n",
              "language      0\n",
              "label         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQBUYZgRogbr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rljKltuj_m2"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DxPCznjdU-M"
      },
      "source": [
        "## Data Tweaks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQoYndYfoQ50"
      },
      "source": [
        "We decided to work only with english sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxlesnU6kKRB"
      },
      "source": [
        "train_df=train_df_orig[train_df_orig['lang_abv']== 'en'].copy()\r\n",
        "test_df=test_df_orig[test_df_orig['lang_abv']== 'en'].copy()\r\n",
        "\r\n",
        "#print( eng_train['lang_abv'].unique() )\r\n",
        "#print( eng_test['lang_abv'].unique() )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bol5lWm_P_vI"
      },
      "source": [
        "COLUMNS_TO_DROP= ['id', 'lang_abv', 'language']\n",
        "\n",
        "for col in COLUMNS_TO_DROP:\n",
        "  train_df.drop(columns= col, inplace= True)\n",
        "  test_df.drop(columns= col, inplace= True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PILKjdFGd-y7"
      },
      "source": [
        "## kFolds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kgKXZl-aG9b",
        "outputId": "55dc5185-0463-4958-b59a-383470cd77d9"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\r\n",
        "\r\n",
        "# initialize kfold\r\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1024)\r\n",
        "\r\n",
        "# Extract labels for stratification\r\n",
        "X, y = train_df[[\"premise\", \"hypothesis\"]], train_df['label']\r\n",
        "\r\n",
        "# Each fold is a tuple ([train_index_values], [val_index_values])\r\n",
        "# fold_0, fold_1, fold_2, fold_3, fold_5 = kf.split(df, y)\r\n",
        "\r\n",
        "# Put the folds into a list. This is a list of tuples.\r\n",
        "fold_list = list(kf.split(X, y))\r\n",
        "\r\n",
        "train_df_list = []\r\n",
        "val_df_list = []\r\n",
        "\r\n",
        "for i, fold in enumerate(fold_list):\r\n",
        "\r\n",
        "    # map the train and val index values to dataframe rows\r\n",
        "    df_train = train_df[train_df.index.isin(fold[0])]\r\n",
        "    df_val = train_df[train_df.index.isin(fold[1])]\r\n",
        "    \r\n",
        "    train_df_list.append(df_train)\r\n",
        "    val_df_list.append(df_val)\r\n",
        "    \r\n",
        "    \r\n",
        "\r\n",
        "print(len(train_df_list))\r\n",
        "print(len(val_df_list))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "edaFerSnf8Wz",
        "outputId": "05cd491f-4aee-43ed-a820-5b554258014c"
      },
      "source": [
        "# Display one train fold\r\n",
        "\r\n",
        "train_df_list[0].head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and these comments were considered in formulat...</td>\n",
              "      <td>The rules developed in the interim were put to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>These are issues that we wrestle with in pract...</td>\n",
              "      <td>Practice groups are not permitted to work on t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>you know they can't really defend themselves l...</td>\n",
              "      <td>They can't defend themselves because of their ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From Cockpit Country to St. Ann's Bay</td>\n",
              "      <td>From St. Ann's Bay to Cockpit Country.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Look, it's your skin, but you're going to be i...</td>\n",
              "      <td>The boss will fire you if he sees you slacking...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             premise  ... label\n",
              "0  and these comments were considered in formulat...  ...     0\n",
              "1  These are issues that we wrestle with in pract...  ...     2\n",
              "3  you know they can't really defend themselves l...  ...     0\n",
              "7              From Cockpit Country to St. Ann's Bay  ...     2\n",
              "8  Look, it's your skin, but you're going to be i...  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfaeLu5ijouY"
      },
      "source": [
        "## Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "MZWtOP1otDhR",
        "outputId": "b93aecaf-5773-45bf-8b10-05ba07c62baa"
      },
      "source": [
        "## Number of words in each premise and hypothesis sentences\r\n",
        "\r\n",
        "premise_len = [len(i.split()) for i in train_df['premise']]\r\n",
        "hypothesis_len = [len(i.split()) for i in train_df['hypothesis']]\r\n",
        "\r\n",
        "for i in [premise_len,hypothesis_len]:\r\n",
        "  pd.Series(i).hist(bins=30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiqfUM-Ui6nn",
        "outputId": "cd0a6ae7-e9c1-45ca-a013-439e6829fadd"
      },
      "source": [
        "MODEL_TYPE = 'bert-base-uncased'\r\n",
        "\r\n",
        "\r\n",
        "L_RATE = 1e-5\r\n",
        "MAX_LEN = 25  ## We took into consideration mean sentence lenght from previous plot.\r\n",
        "FOLDS = 5\r\n",
        "NUM_EPOCHS = 3\r\n",
        "BATCH_SIZE = 32\r\n",
        "NUM_CORES = os.cpu_count()\r\n",
        "\r\n",
        "print(NUM_CORES)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVWOPXBAkhiW",
        "outputId": "911d4f01-9976-4578-8be5-ce9a92764f61"
      },
      "source": [
        "# For GPU\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "print(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "0f69136a36504d6b99490b96108fc56b",
            "7793fb0876d94098a1596db099a67c20",
            "62457700621b4a648af5339656da2c9e",
            "ce26eb9a27394f47b02fc474111e5f9e",
            "6314409480254be7809c5b9166fcee53",
            "aa458488167844ddb83f66aec14fc551",
            "fc91a9301e1f4464953401d0de4e6463",
            "00f81813b319408f9da640eaf22837b3"
          ]
        },
        "id": "tD09rYLatDuV",
        "outputId": "370ae453-02ed-4eb8-fbae-f3a50e697af5"
      },
      "source": [
        "# Load the BERT tokenizer.\r\n",
        "print('Loading BERT tokenizer...')\r\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE, do_lower_case=True)\r\n",
        "print('done!')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f69136a36504d6b99490b96108fc56b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSPff254tDxh",
        "outputId": "d2efa25c-a244-49ea-a249-c573550fe02c"
      },
      "source": [
        "df_train = df_train.reset_index(drop=True)\r\n",
        "df_val = df_val.reset_index(drop=True)\r\n",
        "\r\n",
        "train_data = TokensTensors(df_train)\r\n",
        "val_data = TokensTensors(df_val)\r\n",
        "test_data = TokensTensors(test_df)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\r\n",
        "                                        batch_size=BATCH_SIZE,\r\n",
        "                                        shuffle=True,\r\n",
        "                                       num_workers=NUM_CORES)\r\n",
        "\r\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\r\n",
        "                                        batch_size=BATCH_SIZE,\r\n",
        "                                        shuffle=True,\r\n",
        "                                       num_workers=NUM_CORES)\r\n",
        "\r\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data,\r\n",
        "                                        batch_size=BATCH_SIZE,\r\n",
        "                                        shuffle=False,\r\n",
        "                                       num_workers=NUM_CORES)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(len(train_dataloader))\r\n",
        "print(len(val_dataloader))\r\n",
        "print(len(test_dataloader))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98\n",
            "25\n",
            "93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA0zR5M_z7Ya",
        "outputId": "8f2ba55f-e3e6-4e2f-cc5d-78d4cae2ebb0"
      },
      "source": [
        "# Get one train batch\r\n",
        "\r\n",
        "padded_token_list, att_mask, token_type_ids, target = next(iter(train_dataloader))\r\n",
        "\r\n",
        "print(padded_token_list.shape)\r\n",
        "print(att_mask.shape)\r\n",
        "print(token_type_ids.shape)\r\n",
        "print(target.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 25])\n",
            "torch.Size([32, 25])\n",
            "torch.Size([32, 25])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcepQjNqz7gC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZHbiVQWNoHT"
      },
      "source": [
        "### To verify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3i9KV9MXuTQ",
        "outputId": "50267532-af46-4f56-e913-1d09d2ae4145"
      },
      "source": [
        "# i load my dataset because the eng_train doesn't work here and i don't know why\n",
        "PATH= '/content/drive/My Drive/TA/'\n",
        "df= load_df(PATH, 'eng_train.csv')\n",
        "df.drop(columns='Unnamed: 0', inplace= True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeGvPuS8XyTx",
        "outputId": "34586caf-d633-484f-a85d-14f793f137a9"
      },
      "source": [
        "list_of_sentences= concatenate_sentences( df['premise'], df['hypothesis'] )\n",
        "tagged_data = prepare_input_w2d(list_of_sentences)\n",
        "model = Doc2Vec(tagged_data, vector_size=250, window=5, min_count=10, epochs= 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-27 18:04:17,177 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
            "2020-12-27 18:04:17,180 : INFO : collecting all words and their counts\n",
            "2020-12-27 18:04:17,183 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "2020-12-27 18:04:17,238 : INFO : collected 16817 word types and 6870 unique tags from a corpus of 6870 examples and 215929 words\n",
            "2020-12-27 18:04:17,238 : INFO : Loading a fresh vocabulary\n",
            "2020-12-27 18:04:17,250 : INFO : effective_min_count=10 retains 2367 unique words (14% of original 16817, drops 14450)\n",
            "2020-12-27 18:04:17,251 : INFO : effective_min_count=10 leaves 177774 word corpus (82% of original 215929, drops 38155)\n",
            "2020-12-27 18:04:17,260 : INFO : deleting the raw counts dictionary of 16817 items\n",
            "2020-12-27 18:04:17,261 : INFO : sample=0.001 downsamples 58 most-common words\n",
            "2020-12-27 18:04:17,261 : INFO : downsampling leaves estimated 119554 word corpus (67.3% of prior 177774)\n",
            "2020-12-27 18:04:17,270 : INFO : estimated required memory for 2367 words and 250 dimensions: 14161500 bytes\n",
            "2020-12-27 18:04:17,272 : INFO : resetting layer weights\n",
            "2020-12-27 18:04:19,069 : INFO : training model with 3 workers on 2367 vocabulary and 250 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-12-27 18:04:19,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:19,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:19,900 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:19,901 : INFO : EPOCH - 1 : training on 215929 raw words (126496 effective words) took 0.8s, 153467 effective words/s\n",
            "2020-12-27 18:04:20,699 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:20,708 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:20,721 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:20,722 : INFO : EPOCH - 2 : training on 215929 raw words (126466 effective words) took 0.8s, 155452 effective words/s\n",
            "2020-12-27 18:04:21,508 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:21,513 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:21,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:21,529 : INFO : EPOCH - 3 : training on 215929 raw words (126412 effective words) took 0.8s, 158108 effective words/s\n",
            "2020-12-27 18:04:22,332 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:22,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:22,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:22,353 : INFO : EPOCH - 4 : training on 215929 raw words (126296 effective words) took 0.8s, 154607 effective words/s\n",
            "2020-12-27 18:04:23,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:23,150 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:23,160 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:23,161 : INFO : EPOCH - 5 : training on 215929 raw words (126258 effective words) took 0.8s, 157808 effective words/s\n",
            "2020-12-27 18:04:23,958 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:23,966 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:23,978 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:23,979 : INFO : EPOCH - 6 : training on 215929 raw words (126242 effective words) took 0.8s, 155794 effective words/s\n",
            "2020-12-27 18:04:24,764 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:24,778 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:24,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:24,790 : INFO : EPOCH - 7 : training on 215929 raw words (126568 effective words) took 0.8s, 157437 effective words/s\n",
            "2020-12-27 18:04:25,574 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:25,581 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:25,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:25,598 : INFO : EPOCH - 8 : training on 215929 raw words (126353 effective words) took 0.8s, 157851 effective words/s\n",
            "2020-12-27 18:04:26,394 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:26,402 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:26,418 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:26,418 : INFO : EPOCH - 9 : training on 215929 raw words (126381 effective words) took 0.8s, 155455 effective words/s\n",
            "2020-12-27 18:04:27,193 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:27,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:27,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:27,220 : INFO : EPOCH - 10 : training on 215929 raw words (126470 effective words) took 0.8s, 159328 effective words/s\n",
            "2020-12-27 18:04:28,021 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:28,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:28,041 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:28,042 : INFO : EPOCH - 11 : training on 215929 raw words (126722 effective words) took 0.8s, 155332 effective words/s\n",
            "2020-12-27 18:04:28,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:28,821 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:28,834 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:28,835 : INFO : EPOCH - 12 : training on 215929 raw words (126419 effective words) took 0.8s, 160983 effective words/s\n",
            "2020-12-27 18:04:29,635 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:29,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:29,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:29,662 : INFO : EPOCH - 13 : training on 215929 raw words (126510 effective words) took 0.8s, 154356 effective words/s\n",
            "2020-12-27 18:04:30,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:30,463 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:30,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:30,474 : INFO : EPOCH - 14 : training on 215929 raw words (126424 effective words) took 0.8s, 156941 effective words/s\n",
            "2020-12-27 18:04:31,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:31,293 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:31,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:31,305 : INFO : EPOCH - 15 : training on 215929 raw words (126242 effective words) took 0.8s, 153293 effective words/s\n",
            "2020-12-27 18:04:32,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:32,122 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:32,130 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:32,131 : INFO : EPOCH - 16 : training on 215929 raw words (126288 effective words) took 0.8s, 154337 effective words/s\n",
            "2020-12-27 18:04:32,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:32,927 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:32,941 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:32,942 : INFO : EPOCH - 17 : training on 215929 raw words (126290 effective words) took 0.8s, 157156 effective words/s\n",
            "2020-12-27 18:04:33,729 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:33,739 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:33,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:33,746 : INFO : EPOCH - 18 : training on 215929 raw words (126407 effective words) took 0.8s, 158600 effective words/s\n",
            "2020-12-27 18:04:34,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:34,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:34,566 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:34,567 : INFO : EPOCH - 19 : training on 215929 raw words (126516 effective words) took 0.8s, 155702 effective words/s\n",
            "2020-12-27 18:04:35,369 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:35,379 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:35,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:35,392 : INFO : EPOCH - 20 : training on 215929 raw words (126572 effective words) took 0.8s, 154827 effective words/s\n",
            "2020-12-27 18:04:36,197 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:36,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:36,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:36,224 : INFO : EPOCH - 21 : training on 215929 raw words (126248 effective words) took 0.8s, 153067 effective words/s\n",
            "2020-12-27 18:04:36,998 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:37,015 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:37,027 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:37,028 : INFO : EPOCH - 22 : training on 215929 raw words (126364 effective words) took 0.8s, 158633 effective words/s\n",
            "2020-12-27 18:04:37,824 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:37,830 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:37,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:37,846 : INFO : EPOCH - 23 : training on 215929 raw words (126294 effective words) took 0.8s, 155907 effective words/s\n",
            "2020-12-27 18:04:38,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:38,649 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:38,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:38,654 : INFO : EPOCH - 24 : training on 215929 raw words (126312 effective words) took 0.8s, 157766 effective words/s\n",
            "2020-12-27 18:04:39,458 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:39,466 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:39,481 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:39,481 : INFO : EPOCH - 25 : training on 215929 raw words (126553 effective words) took 0.8s, 154382 effective words/s\n",
            "2020-12-27 18:04:40,295 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:40,312 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:40,322 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:40,323 : INFO : EPOCH - 26 : training on 215929 raw words (126510 effective words) took 0.8s, 151457 effective words/s\n",
            "2020-12-27 18:04:41,136 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:41,144 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:41,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:41,156 : INFO : EPOCH - 27 : training on 215929 raw words (126243 effective words) took 0.8s, 153012 effective words/s\n",
            "2020-12-27 18:04:41,940 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:41,966 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:41,972 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:41,973 : INFO : EPOCH - 28 : training on 215929 raw words (126404 effective words) took 0.8s, 156120 effective words/s\n",
            "2020-12-27 18:04:42,756 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:42,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:42,778 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:42,779 : INFO : EPOCH - 29 : training on 215929 raw words (126532 effective words) took 0.8s, 158360 effective words/s\n",
            "2020-12-27 18:04:43,587 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:43,588 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:43,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:43,606 : INFO : EPOCH - 30 : training on 215929 raw words (126623 effective words) took 0.8s, 154704 effective words/s\n",
            "2020-12-27 18:04:44,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:44,412 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:44,428 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:44,429 : INFO : EPOCH - 31 : training on 215929 raw words (126257 effective words) took 0.8s, 154886 effective words/s\n",
            "2020-12-27 18:04:45,214 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:45,224 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:45,237 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:45,237 : INFO : EPOCH - 32 : training on 215929 raw words (126321 effective words) took 0.8s, 157777 effective words/s\n",
            "2020-12-27 18:04:46,051 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:46,057 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:46,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:46,066 : INFO : EPOCH - 33 : training on 215929 raw words (126342 effective words) took 0.8s, 153980 effective words/s\n",
            "2020-12-27 18:04:46,845 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:46,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:46,865 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:46,866 : INFO : EPOCH - 34 : training on 215929 raw words (126264 effective words) took 0.8s, 159158 effective words/s\n",
            "2020-12-27 18:04:47,663 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:47,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:47,686 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:47,687 : INFO : EPOCH - 35 : training on 215929 raw words (126575 effective words) took 0.8s, 155881 effective words/s\n",
            "2020-12-27 18:04:48,465 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:48,476 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:48,490 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:48,491 : INFO : EPOCH - 36 : training on 215929 raw words (126412 effective words) took 0.8s, 158673 effective words/s\n",
            "2020-12-27 18:04:49,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:49,288 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:49,300 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:49,301 : INFO : EPOCH - 37 : training on 215929 raw words (126350 effective words) took 0.8s, 157396 effective words/s\n",
            "2020-12-27 18:04:50,057 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:50,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:50,094 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:50,094 : INFO : EPOCH - 38 : training on 215929 raw words (126549 effective words) took 0.8s, 160903 effective words/s\n",
            "2020-12-27 18:04:50,907 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:50,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:50,926 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:50,927 : INFO : EPOCH - 39 : training on 215929 raw words (126450 effective words) took 0.8s, 154428 effective words/s\n",
            "2020-12-27 18:04:51,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:51,743 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:51,760 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:51,761 : INFO : EPOCH - 40 : training on 215929 raw words (126183 effective words) took 0.8s, 152332 effective words/s\n",
            "2020-12-27 18:04:52,548 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:52,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:52,568 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:52,569 : INFO : EPOCH - 41 : training on 215929 raw words (126450 effective words) took 0.8s, 157968 effective words/s\n",
            "2020-12-27 18:04:53,351 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:53,368 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:53,379 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:53,380 : INFO : EPOCH - 42 : training on 215929 raw words (126628 effective words) took 0.8s, 157544 effective words/s\n",
            "2020-12-27 18:04:54,186 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:54,196 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:54,210 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:54,211 : INFO : EPOCH - 43 : training on 215929 raw words (126371 effective words) took 0.8s, 153496 effective words/s\n",
            "2020-12-27 18:04:54,991 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:55,003 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:55,010 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:55,011 : INFO : EPOCH - 44 : training on 215929 raw words (126497 effective words) took 0.8s, 159596 effective words/s\n",
            "2020-12-27 18:04:55,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:55,802 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:55,815 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:55,816 : INFO : EPOCH - 45 : training on 215929 raw words (126494 effective words) took 0.8s, 158625 effective words/s\n",
            "2020-12-27 18:04:56,609 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:56,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:56,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:56,637 : INFO : EPOCH - 46 : training on 215929 raw words (126353 effective words) took 0.8s, 155402 effective words/s\n",
            "2020-12-27 18:04:57,413 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:57,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:57,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:57,440 : INFO : EPOCH - 47 : training on 215929 raw words (126430 effective words) took 0.8s, 158786 effective words/s\n",
            "2020-12-27 18:04:58,265 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:58,267 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:58,280 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:58,281 : INFO : EPOCH - 48 : training on 215929 raw words (126443 effective words) took 0.8s, 151671 effective words/s\n",
            "2020-12-27 18:04:59,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:59,093 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:59,105 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:59,106 : INFO : EPOCH - 49 : training on 215929 raw words (126384 effective words) took 0.8s, 154648 effective words/s\n",
            "2020-12-27 18:04:59,878 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-12-27 18:04:59,902 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-12-27 18:04:59,912 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-12-27 18:04:59,913 : INFO : EPOCH - 50 : training on 215929 raw words (126472 effective words) took 0.8s, 158140 effective words/s\n",
            "2020-12-27 18:04:59,915 : INFO : training on a 10796450 raw words (6320640 effective words) took 40.8s, 154760 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "11F8zFbvTgA7",
        "outputId": "28ae104f-4fea-48ea-c3e6-eba0c1b87e91"
      },
      "source": [
        "#list_of_sentences= concatenate_sentences( eng_train['premise'], eng_train['hypothesis'] )\n",
        "#tagged_data = prepare_input_w2d(list_of_sentences)\n",
        "#model = Doc2Vec(tagged_data, vector_size=250, window=5, min_count=10, epochs= 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 2",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-127839386d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_of_sentences\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconcatenate_sentences\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0meng_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'premise'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hypothesis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input_w2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-b9ce0fd38e46>\u001b[0m in \u001b[0;36mconcatenate_sentences\u001b[0;34m(col_1, col_2)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcol_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MX0jQOiqVO5"
      },
      "source": [
        "# Classic Machine Learning Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIb7d-uLqgC8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLCRo-lTqgdT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE744IEhqhQX"
      },
      "source": [
        "# BERT Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NIHYPV5qo91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d110fba-a432-4774-ec7d-14971a009410"
      },
      "source": [
        "!pip install bert-for-tf2\r\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/d3/820ccaf55f1e24b5dd43583ac0da6d86c2d27bbdfffadbba69bafe73ca93/bert-for-tf2-0.14.7.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 27.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.7-cp36-none-any.whl size=30537 sha256=0c062f0726bf0af2f9829c1db013f15a411426003d9350bc90f726235b9ee45f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/f8/e2/b98f79a6b8cc898d8e4102b83acb8a098df7d27500a2bac912\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7303 sha256=b60b7990a812fdb989a37f0c94c625c6d62fe0cda5d54e9e21d0b0a8f6e371dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19474 sha256=a82d87ad6271e1e75f9264875a664bd97aef3660ae3195827c5f153d9b863a3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.7 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 9.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS2WcjoIqpBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf37f072-4b47-4082-cfa9-71555c4ba22d"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow\r\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMUnJYrO22Ea"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "542ea83b34a64b8e8651b8a32c6236d6",
            "1d6c32e2a68d4b4c948e3fc4d401a8ab",
            "587ec64aae6e4eb5aa63fb1c0af2dd65",
            "45d4bebdef074fd6b1c07eaf868f670d",
            "455c523fa7354e158876aa1ef2ec1d70",
            "f8771dec778540d484362d2877f34d4e",
            "edf53b600eea44b1b83cdb46494aa34b",
            "bffaf67cfd6d4430816d5aaa3b542780",
            "3580bffd19534129a52e6306ccb858b1",
            "ac544c4718fd4bdb852a3ee881a712c6",
            "0e5044ab630345e2be10c542313964ea",
            "bf8431f64ade4b9ea469cbd26a814801",
            "64308d2811b54e159af7ba0d901da5a4",
            "ecb44e43bf7f4cdab17406acc813dd31",
            "285a28208a4c4362b29aeec70d824588",
            "557dee5054a24e6caad8598ec4635d5d"
          ]
        },
        "id": "V7notzzFFrDM",
        "outputId": "a4cf67d8-e130-489b-880f-473328fdf011"
      },
      "source": [
        "# import BERT-base pretrained model\r\n",
        "bert = AutoModel.from_pretrained(MODEL_TYPE)\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "542ea83b34a64b8e8651b8a32c6236d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3580bffd19534129a52e6306ccb858b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R0y1fwFHEwL"
      },
      "source": [
        "# freeze all the parameters\r\n",
        "for param in bert.parameters():\r\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRqZVz0rHI7K"
      },
      "source": [
        "class BERT_Arch(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, bert):\r\n",
        "      \r\n",
        "      super(BERT_Arch, self).__init__()\r\n",
        "\r\n",
        "      self.bert = bert \r\n",
        "      \r\n",
        "      # dropout layer\r\n",
        "      self.dropout = nn.Dropout(0.1)\r\n",
        "      \r\n",
        "      # relu activation function\r\n",
        "      self.relu =  nn.ReLU()\r\n",
        "\r\n",
        "      # dense layer 1\r\n",
        "      self.fc1 = nn.Linear(768,512)\r\n",
        "      \r\n",
        "      # dense layer 2 (Output layer)\r\n",
        "      self.fc2 = nn.Linear(512,2)\r\n",
        "\r\n",
        "      #softmax activation function\r\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\r\n",
        "\r\n",
        "    #define the forward pass\r\n",
        "    def forward(self, sent_id, mask):\r\n",
        "\r\n",
        "      #pass the inputs to the model  \r\n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\r\n",
        "      \r\n",
        "      x = self.fc1(cls_hs)\r\n",
        "\r\n",
        "      x = self.relu(x)\r\n",
        "\r\n",
        "      x = self.dropout(x)\r\n",
        "\r\n",
        "      # output layer\r\n",
        "      x = self.fc2(x)\r\n",
        "      \r\n",
        "      # apply softmax activation\r\n",
        "      x = self.softmax(x)\r\n",
        "\r\n",
        "      return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDATeBdIHI93"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\r\n",
        "model = BERT_Arch(bert)\r\n",
        "\r\n",
        "# push the model to GPU\r\n",
        "model = model.to(device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XOQ1ApPHJBJ"
      },
      "source": [
        "\r\n",
        "# optimizer from hugging face transformers\r\n",
        "from transformers import AdamW\r\n",
        "\r\n",
        "# define the optimizer\r\n",
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = L_RATE)          # learning rate"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_b3wUXbJw0X",
        "outputId": "b175a1f5-f6cb-4e84-8fa0-011aea4a6adf"
      },
      "source": [
        " enumerate(train_dataloader)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<enumerate at 0x7f96c882f870>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Iyi4-RHJEV"
      },
      "source": [
        "# function to train the model\r\n",
        "def train():\r\n",
        "  \r\n",
        "  model.train()\r\n",
        "\r\n",
        "  total_loss, total_accuracy = 0, 0\r\n",
        "  \r\n",
        "  # empty list to save model predictions\r\n",
        "  total_preds=[]\r\n",
        "  \r\n",
        "  # iterate over batches\r\n",
        "  for step,batch in enumerate(train_dataloader):\r\n",
        "    \r\n",
        "    # progress update after every 50 batches.\r\n",
        "    if step % 50 == 0 and not step == 0:\r\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\r\n",
        "\r\n",
        "    # push the batch to gpu\r\n",
        "    batch = [r.to(device) for r in batch]\r\n",
        " \r\n",
        "    sent_id, mask, labels = batch\r\n",
        "\r\n",
        "    # clear previously calculated gradients \r\n",
        "    model.zero_grad()        \r\n",
        "\r\n",
        "    # get model predictions for the current batch\r\n",
        "    preds = model(sent_id, mask)\r\n",
        "\r\n",
        "    # compute the loss between actual and predicted values\r\n",
        "    loss = cross_entropy(preds, labels)\r\n",
        "\r\n",
        "    # add on to the total loss\r\n",
        "    total_loss = total_loss + loss.item()\r\n",
        "\r\n",
        "    # backward pass to calculate the gradients\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "    # update parameters\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # model predictions are stored on GPU. So, push it to CPU\r\n",
        "    preds=preds.detach().cpu().numpy()\r\n",
        "\r\n",
        "    # append the model predictions\r\n",
        "    total_preds.append(preds)\r\n",
        "\r\n",
        "  # compute the training loss of the epoch\r\n",
        "  avg_loss = total_loss / len(train_dataloader)\r\n",
        "  \r\n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\r\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\r\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\r\n",
        "\r\n",
        "  #returns the loss and predictions\r\n",
        "  return avg_loss, total_predsa"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yB_OzShHJHQ"
      },
      "source": [
        "# function for evaluating the model\r\n",
        "def evaluate():\r\n",
        "  \r\n",
        "  print(\"\\nEvaluating...\")\r\n",
        "  \r\n",
        "  # deactivate dropout layers\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  total_loss, total_accuracy = 0, 0\r\n",
        "  \r\n",
        "  # empty list to save the model predictions\r\n",
        "  total_preds = []\r\n",
        "\r\n",
        "  # iterate over batches\r\n",
        "  for step,batch in enumerate(val_dataloader):\r\n",
        "    \r\n",
        "    # Progress update every 50 batches.\r\n",
        "    if step % 50 == 0 and not step == 0:\r\n",
        "      \r\n",
        "      # Calculate elapsed time in minutes.\r\n",
        "      elapsed = format_time(time.time() - t0)\r\n",
        "            \r\n",
        "      # Report progress.\r\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\r\n",
        "\r\n",
        "    # push the batch to gpu\r\n",
        "    batch = [t.to(device) for t in batch]\r\n",
        "\r\n",
        "    sent_id, mask, labels = batch\r\n",
        "\r\n",
        "    # deactivate autograd\r\n",
        "    with torch.no_grad():\r\n",
        "      \r\n",
        "      # model predictions\r\n",
        "      preds = model(sent_id, mask)\r\n",
        "\r\n",
        "      # compute the validation loss between actual and predicted values\r\n",
        "      loss = cross_entropy(preds,labels)\r\n",
        "\r\n",
        "      total_loss = total_loss + loss.item()\r\n",
        "\r\n",
        "      preds = preds.detach().cpu().numpy()\r\n",
        "\r\n",
        "      total_preds.append(preds)\r\n",
        "\r\n",
        "  # compute the validation loss of the epoch\r\n",
        "  avg_loss = total_loss / len(val_dataloader) \r\n",
        "\r\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\r\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\r\n",
        "\r\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "6q-Os-FKHJRi",
        "outputId": "20f5f78a-4278-4a0d-beaa-8fd6286f0e74"
      },
      "source": [
        "epochs = NUM_EPOCHS\r\n",
        "# set initial loss to infinite\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "# empty lists to store training and validation loss of each epoch\r\n",
        "train_losses=[]\r\n",
        "valid_losses=[]\r\n",
        "\r\n",
        "#for each epoch\r\n",
        "for epoch in range(epochs):\r\n",
        "     \r\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\r\n",
        "    \r\n",
        "    #train model\r\n",
        "    train_loss, _ = train()\r\n",
        "    \r\n",
        "    #evaluate model\r\n",
        "    valid_loss, _ = evaluate()\r\n",
        "    \r\n",
        "    #save the best model\r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "    \r\n",
        "    # append training and validation loss\r\n",
        "    train_losses.append(train_loss)\r\n",
        "    valid_losses.append(valid_loss)\r\n",
        "    \r\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\r\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-829db8e66162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-a8875e82e2a3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# iterate over batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# progress update after every 50 batches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [20] at entry 0 and [14] at entry 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8d6uwDXHxqh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpOxcOF8HxxA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsLXqWSsHx3i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A6hUiVxHx6M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyFGTwpzHx8_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70sCfW0HHyEH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNpGl-7WHyG9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5gadRORHyJu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRltFLaZLvVA",
        "outputId": "96752c81-7048-4432-9f8b-50f1b748ac3c"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \r\n",
        "# linear classification layer on top. \r\n",
        "model = BertForSequenceClassification.from_pretrained(\r\n",
        "    MODEL_TYPE, \r\n",
        "    num_labels = 3, \r\n",
        "    output_attentions = False,\r\n",
        "    output_hidden_states = False)\r\n",
        "\r\n",
        "# Send the model to the device.\r\n",
        "model.to(device)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAPYz-ZTLvrM",
        "outputId": "e16b1358-76fd-4fef-9879-f9f9ce87db59"
      },
      "source": [
        "# Get one train batch\r\n",
        "\r\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\r\n",
        "                                        batch_size=8,\r\n",
        "                                        shuffle=True,\r\n",
        "                                       num_workers=NUM_CORES)\r\n",
        "\r\n",
        "batch = next(iter(train_dataloader))\r\n",
        "\r\n",
        "b_input_ids = batch[0].to(device)\r\n",
        "b_input_mask = batch[1].to(device)\r\n",
        "b_token_type_ids = batch[2].to(device)\r\n",
        "b_labels = batch[3].to(device)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi7xD5S5Lvxq"
      },
      "source": [
        "outputs = model(b_input_ids, \r\n",
        "                token_type_ids=b_token_type_ids, \r\n",
        "                attention_mask=b_input_mask,\r\n",
        "                labels=b_labels)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aofckaBmLv0p",
        "outputId": "13184805-2462-4f0c-eae7-c8d7637ed4a4"
      },
      "source": [
        "outputs"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput([('loss',\n",
              "                           tensor(1.1779, device='cuda:0', grad_fn=<NllLossBackward>)),\n",
              "                          ('logits', tensor([[ 0.4013, -0.0353, -0.1948],\n",
              "                                   [ 0.5057, -0.2213, -0.3892],\n",
              "                                   [ 0.4056, -0.2278, -0.3850],\n",
              "                                   [ 0.1799,  0.2544, -0.0730],\n",
              "                                   [ 0.4171, -0.2556, -0.4248],\n",
              "                                   [ 0.4508, -0.2361, -0.4016],\n",
              "                                   [ 0.4249, -0.2569, -0.4329],\n",
              "                                   [ 0.4396, -0.2416, -0.4222]], device='cuda:0', grad_fn=<AddmmBackward>))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ66_4ReLv4m",
        "outputId": "2c91c0d2-6c8c-4b86-dd2a-c4a0fd5970f0"
      },
      "source": [
        "preds = outputs[1].detach().cpu().numpy()\r\n",
        "\r\n",
        "y_true = b_labels.detach().cpu().numpy()\r\n",
        "y_pred = np.argmax(preds, axis=1)\r\n",
        "\r\n",
        "y_pred"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evC_2-bCLv7x",
        "outputId": "406190b9-38f9-40bd-f031-4b83d641c183"
      },
      "source": [
        "# This is the accuracy without any fine tuning.\r\n",
        "\r\n",
        "val_acc = accuracy_score(y_true, y_pred)\r\n",
        "\r\n",
        "val_acc"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "9SWWD_RXLv_p",
        "outputId": "6ed0befb-02ca-4cd4-b3f0-5380e1d0845d"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Num folds used for training: 3\n",
            "======== Epoch 1 / 3 ========\n",
            "\n",
            "== Fold Model 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-885690eec1dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n\\n# Set a seed value.\\nseed_val = 1024\\n\\nrandom.seed(seed_val)\\nnp.random.seed(seed_val)\\ntorch.manual_seed(seed_val)\\ntorch.cuda.manual_seed_all(seed_val)\\n\\n\\n\\n# Store the accuracy scores for each fold model in this list.\\n# [[model_0 scores], [model_1 scores], [model_2 scores], [model_3 scores], [model_4 scores]]\\n# [[ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...]]\\n\\n# Create a list of lists to store the val acc results.\\n# The number of items in this list will correspond to\\n# the number of folds that the model is being trained on.\\nfold_val_acc_list = []\\nfor i in range(0, NUM_FOLDS):\\n    \\n    # append an empty list\\n    fold_val_acc_list.append([])\\n    \\n    \\n    \\n    \\n\\n# For each epoch...\\nfor epoch in range(0, NUM_EPOCHS):\\n    \\n    print(\"\\\\nNum folds used for training:\", NUM_FOLDS_TO_TRAIN)\\n    print(\\'======== Epoch {:} / {:} ========\\'.format(epoch + 1, NUM_EPOCHS))\\n    \\n    # Get the number of folds\\n    num_folds = len(train_df_list)\\n\\n    # For this epoch, store the val acc scores for each fold in this list.\\n    # We will use this list to calculate the cv at the end of the epoch.\\n    epoch_acc_scores_list = []\\n    \\n    # For each fold...\\n    for fold_index in range(0, NUM_FOLDS_TO_TRAI...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\nTypeError: 'DataLoader' object does not support indexing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nfn-412LwDi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PhXLeNpLwHQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o-SZADVLwLb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWqcvZwJHssV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}